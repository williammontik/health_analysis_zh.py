# -*- coding: utf-8 -*-
import os
import logging
import traceback
import re
from datetime import datetime
from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import OpenAI
import concurrent.futures # Import the library for concurrency

app = Flask(__name__)
CORS(app)
logging.basicConfig(level=logging.INFO)

# --- CONFIGURATION (Same as before) ---
try:
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    logging.info("OpenAI client initialized successfully.")
except Exception as e:
    logging.critical(f"OpenAI API key not found or invalid. Error: {e}")
    client = None

# --- LANGUAGE DATA & PROMPTS (Same as before) ---
LABELS_ZH = {
    "summary_title": "ğŸ§  æ‘˜è¦:",
    "suggestions_title": "ğŸ’¡ åˆ›æ„å»ºè®®:"
}
# The build_summary_prompt_zh and build_suggestions_prompt_zh functions are the same as before.

# --- HELPER FUNCTIONS (Same as before) ---
def compute_age(dob_year):
    try:
        return datetime.now().year - int(dob_year)
    except (ValueError, TypeError):
        return 0

def get_openai_response(prompt, temp=0.75):
    if not client:
        raise Exception("OpenAI client not initialized.")
    try:
        result = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=temp,
            max_tokens=1200
        )
        return result.choices[0].message.content
    except Exception as e:
        logging.error(f"OpenAI API call failed: {e}")
        return "âš ï¸ AIå“åº”ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚"

# --- CHINESE API ENDPOINT (REVISED FOR CONCURRENCY) ---
@app.route("/health_analyze_zh", methods=["POST"])
def health_analyze_zh():
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "æ— æ•ˆè¯·æ±‚ã€‚æœªæ”¶åˆ°JSONæ•°æ®ã€‚"}), 400

        required_fields = ["dob_year", "gender", "country", "condition", "details"]
        missing_fields = [f for f in required_fields if not data.get(f)]
        if missing_fields:
            return jsonify({"error": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}"}), 400

        age = compute_age(data.get("dob_year"))
        details = data.get("details", "æ— ").replace("'''", "'")
        gender = data.get("gender")
        country = data.get("country")
        condition = data.get("condition")

        # --- OPTIMIZATION: RUN ALL AI CALLS CONCURRENTLY ---
        with concurrent.futures.ThreadPoolExecutor() as executor:
            # Step 1: Define all the prompts first
            chart_prompt = (
                f"ä¸€ä½{age}å²æ¥è‡ª{country}çš„{gender}æœ‰å¥åº·é—®é¢˜ï¼šâ€œ{condition}â€ï¼Œ"
                f"è¡¥å……è¯´æ˜ï¼šâ€œ{details}â€ã€‚è¯·ä¸ºæ­¤æ¡£æ¡ˆç”Ÿæˆ3ä¸ªä¸åŒçš„å¥åº·æŒ‡æ ‡ç±»åˆ«ã€‚æ¯ä¸ªç±»åˆ«å¿…é¡»ä»¥â€œ###â€å¼€å¤´ï¼Œ"
                f"å¹¶æœ‰3ä¸ªæ ¼å¼ä¸ºâ€œæŒ‡æ ‡åç§°: æ•°å€¼%â€çš„æŒ‡æ ‡ã€‚æ•°å€¼å¿…é¡»åœ¨25-90ä¹‹é—´ã€‚è¯·ä»…ç”¨ç®€ä½“ä¸­æ–‡å›ç­”ã€‚"
            )
            # We need the metrics first to create the other prompts
            metrics_content = get_openai_response(chart_prompt)
            metrics = parse_metrics_from_content_zh(metrics_content)

            summary_prompt = build_summary_prompt_zh(age, gender, country, condition, details, metrics)
            suggestions_prompt = build_suggestions_prompt_zh(age, gender, country, condition, details)

            # Step 2: Submit the summary and suggestions tasks to run at the same time
            future_summary = executor.submit(get_openai_response, summary_prompt)
            future_creative = executor.submit(get_openai_response, suggestions_prompt, temp=0.85)

            # Step 3: Get the results when they are ready
            summary = future_summary.result()
            creative = future_creative.result()
        # --- END OF OPTIMIZATION ---

        # Step 4: Build the HTML response (this logic is unchanged)
        summary_paragraphs = [p.strip() for p in summary.split('\n') if p.strip()]
        html_result = f"<div style='font-size:24px; font-weight:bold; margin-top:30px;'>{LABELS_ZH['summary_title']}</div><br>"
        html_result += ''.join(f"<p style='line-height:1.7; font-size:16px; margin-bottom:16px;'>{p}</p>" for p in summary_paragraphs)
        
        html_result += f"<div style='font-size:24px; font-weight:bold; margin-top:30px;'>{LABELS_ZH['suggestions_title']}</div><br>"
        html_result += ''.join(f"<p style='margin:16px 0; font-size:17px;'>{line}</p>" for line in creative.split("\n") if line.strip())

        footer_html = f"""
        <div style="margin-top: 40px; padding: 20px; background-color: #f8f9fa; border-radius: 8px; font-family: sans-serif; border-left: 6px solid #4CAF50;">
            <h4 style="font-size: 16px; font-weight: bold; margin-top: 0; margin-bottom: 15px; display: flex; align-items: center;">
                ğŸ“Š ç”± KataChat AI ç”Ÿæˆçš„å¥åº·æ´å¯Ÿ
            </h4>
            <p style="font-size: 14px; color: #333; line-height: 1.6;">
                æœ¬å¥åº·æŠ¥å‘ŠåŸºäº KataChat çš„ä¸“æœ‰AIæ¨¡å‹ç”Ÿæˆï¼Œå…¶æ•°æ®æ¥æºåŒ…æ‹¬:
            </p>
            <ul style="font-size: 14px; color: #555; padding-left: 20px; margin-top: 10px; margin-bottom: 20px; line-height: 1.6;">
                <li>æ¥è‡ªæ–°åŠ å¡ã€é©¬æ¥è¥¿äºšå’Œå°æ¹¾åœ°åŒºä¸ªäººçš„åŒ¿ååŒ–å¥åº·ä¸ç”Ÿæ´»æ–¹å¼æ¡£æ¡ˆçš„å®‰å…¨æ•°æ®åº“</li>
                <li>æ¥è‡ªå¯ä¿¡çš„OpenAIç ”ç©¶æ•°æ®é›†çš„èšåˆå…¨çƒå¥åº·åŸºå‡†ä¸è¡Œä¸ºè¶‹åŠ¿æ•°æ®</li>
            </ul>
            <p style="font-size: 14px; color: #333; line-height: 1.6;">
                æ‰€æœ‰åˆ†æå‡ä¸¥æ ¼éµå®ˆPDPAæ³•è§„ï¼Œä»¥ä¿æŠ¤æ‚¨çš„ä¸ªäººæ•°æ®ï¼ŒåŒæ—¶å‘æ˜æœ‰æ„ä¹‰çš„å¥åº·æ´å¯Ÿã€‚
            </p>
            <p style="font-size: 14px; color: #333; line-height: 1.6; margin-top: 20px;">
                <strong>ğŸ—’ï¸ è¯·æ³¨æ„:</strong> æœ¬æŠ¥å‘ŠéåŒ»ç–—è¯Šæ–­ã€‚è‹¥æœ‰ä»»ä½•ä¸¥é‡çš„å¥åº·é—®é¢˜ï¼Œè¯·å’¨è¯¢æ‰§ä¸šåŒ»ç–—ä¸“ä¸šäººå£«ã€‚
            </p>
            <p style="font-size: 14px; color: #333; line-height: 1.6; margin-top: 20px;">
                <strong>PS:</strong> ä¸€ä»½ä¸ªæ€§åŒ–çš„æŠ¥å‘Šä¹Ÿå°†å‘é€åˆ°æ‚¨çš„ç”µå­é‚®ç®±ï¼Œé¢„è®¡åœ¨24-48å°æ—¶å†…é€è¾¾ã€‚å¦‚æœæ‚¨æƒ³æ›´è¯¦ç»†åœ°æ¢è®¨åˆ†æç»“æœï¼Œæˆ‘ä»¬å¾ˆä¹æ„å®‰æ’ä¸€ä¸ª15åˆ†é’Ÿçš„ç®€çŸ­é€šè¯ã€‚
            </p>
        </div>
        """
        html_result += footer_html
        
        return jsonify({"metrics": metrics, "html_result": html_result})

    except Exception as e:
        logging.error(f"An unexpected error occurred in /health_analyze_zh: {e}")
        traceback.print_exc()
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚"}), 500

# You need to add this new helper function to your file
def parse_metrics_from_content_zh(content):
    """Parses the raw string from AI into the metrics list structure."""
    metrics, current_title, labels, values = [], "", [], []
    for line in content.strip().split("\n"):
        line = line.strip()
        if not line: continue
        if line.startswith("###"):
            if current_title and labels:
                metrics.append({"title": current_title, "labels": labels, "values": values})
            current_title = line.replace("###", "").strip()
            labels, values = [], []
        elif ":" in line:
            try:
                label, val_str = line.split(":", 1)
                val_match = re.search(r'\d+', val_str)
                if val_match:
                    labels.append(label.strip())
                    values.append(int(val_match.group(0)))
            except (ValueError, IndexError):
                continue
    if current_title and labels:
        metrics.append({"title": current_title, "labels": labels, "values": values})
    if not metrics:
        return [{"title": "é»˜è®¤æŒ‡æ ‡", "labels": ["æ•°æ®ç‚¹A", "æ•°æ®ç‚¹B", "æ•°æ®ç‚¹C"], "values": [65, 75, 85]}]
    return metrics


if __name__ == "__main__":
    port = int(os.getenv("PORT", 5003))
    app.run(debug=True, port=port, host="0.0.0.0")
